data_list: /this/is/a/test
data_dir: /this/is/also/a/test
verbose: True
log_dir: /log/dir

commit=${commit:=$(git rev-parse HEAD | cut -c1-6)}
	
data_dir: '/local/ubuntu/jon/dev/data_full/data'
data_list: '/home/ubuntu/jon/dev/data_full/data_train.txt'
learning_rate: .001
gpu: 0
max_data_sets: 20
batch_size: 8
num_epochs: 20
num_workers: 1
max_queue_size: 1
use_multiprocessing: False
steps_per_epoch: None
shuffle: True
batch_norm: False
learn_residual: False
gen_type: 'legacy'
slices_per_input: 1
file_ext: 'h5'
random_seed: 723
val_split: 0
log_dir: '/local/logs_tb'
history_file: '/local/history'
checkpoint: '/local/checkpoints'
CHECKPOINT_DIR=${CHECKPOINT_DIR:="/local/checkpoints"}
L1_LAMBDA=${L1_LAMBDA:="1."}
SSIM_LAMBDA=${SSIM_LAMBDA:="0."}

if [[ ${LEARN_RESIDUAL} -eq "0" ]] ; then
	learn_residual_str=" "
else
	learn_residual_str="--learn_residual"
fi

if [[ ${MULTIPROCESSING} -eq "0" ]] ; then
	multiprocessing_str=" "
else
	multiprocessing_str="--use_multiprocessing"
fi

if [[ ${SPLIT} -eq "0" ]] ; then
	split_str=" "
else
	split_str="--gen_type split"
fi

if [[ ${STEPS_PER_EPOCH} -eq "0" ]] ; then
	steps_per_epoch_str=" "
else
	steps_per_epoch_str="--steps_per_epoch ${STEPS_PER_EPOCH}"

fi

if [[ ${SHUFFLE} -eq "0" ]] ; then
	shuffle_str=" "
else
	shuffle_str="--shuffle"

fi

if [[ ${BATCH_NORM} -eq "0" ]] ; then
	batch_norm_str=" "
else
	batch_norm_str="--batch_norm"

fi



cmd="python train.py --data_dir ${DATA_DIR} --data_list ${DATA_LIST} --file_ext ${FILE_EXT} ${steps_per_epoch_str} ${shuffle_str} ${batch_norm_str} ${learn_residual_str} ${split_str} ${multiprocessing_str} --num_epochs ${NUM_EPOCHS} --num_workers ${NUM_WORKERS} --max_queue_size ${QUEUE_SIZE} --verbose --max_data_sets ${MAX_DATA_SETS} --batch_size ${BATCH_SIZE} --validation_split ${VAL_SPLIT} --learning_rate ${LEARNING_RATE} --slices_per_input ${SLICES_PER_INPUT} --random_seed ${RANDOM_SEED} --l1_lambda ${L1_LAMBDA} --ssim_lambda ${SSIM_LAMBDA}"

job_id=$(echo $cmd | sha1sum | awk '{print $1}' | cut -c1-6)

checkpoint_file="${commit}_${job_id}.checkpoint"
log_file="log_${commit}_${job_id}.out"
history_file="history_${commit}_${job_id}.npy"

python train.py --data_dir ${DATA_DIR} --data_list ${DATA_LIST} --file_ext ${FILE_EXT} ${steps_per_epoch_str} ${shuffle_str} ${batch_norm_str} ${learn_residual_str} ${split_str} ${multiprocessing_str} --num_epochs ${NUM_EPOCHS} --num_workers ${NUM_WORKERS} --max_queue_size ${QUEUE_SIZE} --verbose --max_data_sets ${MAX_DATA_SETS} --batch_size ${BATCH_SIZE} --validation_split ${VAL_SPLIT} --learning_rate ${LEARNING_RATE} --slices_per_input ${SLICES_PER_INPUT} --random_seed ${RANDOM_SEED} --l1_lambda ${L1_LAMBDA} --ssim_lambda ${SSIM_LAMBDA} --gpu ${GPU} --checkpoint ${CHECKPOINT_DIR}/${checkpoint_file} --log_dir ${TB_DIR} --history_file ${HIST_DIR}/${history_file} --id ${job_id} > ${LOG_DIR}/${log_file} 2>&1
