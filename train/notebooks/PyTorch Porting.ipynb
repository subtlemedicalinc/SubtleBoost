{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d4fe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import shutil\n",
    "import io\n",
    "import os\n",
    "from subtle.utils.io import load_file\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sigpy as sp\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from subtle.data_loaders.slice_loader import SliceLoader\n",
    "import subtle.subtle_metrics as sumetrics\n",
    "import subtle.utils.io as suio\n",
    "from subtle.utils.experiment import get_config, get_experiment_data\n",
    "import sigpy as sp\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from train import eval_model\n",
    "from glob import glob\n",
    "from subtle.subtle_preprocess import dcm_to_sitk\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torchvision.transforms.functional import resize\n",
    "import pandas as pd\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "\n",
    "plt.set_cmap('gray')\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def process_mpr_sag(vol, plane):\n",
    "    if plane == 'ax':\n",
    "        tr = (1, 0, 2)\n",
    "        x1 = 0\n",
    "    else:\n",
    "        tr = (2, 0, 1)\n",
    "        x1 = 0\n",
    "    vol = vol.transpose(tr)\n",
    "    vol = np.rot90(vol, k=3, axes=(1, 2))\n",
    "    vol = sp.util.resize(vol, [vol.shape[0], vol.shape[1], 240])\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/data/Patient_0085_full.npy')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/slices/Patient_0088/ax/154.npy')[2]\n",
    "print(sl.min(), sl.max())\n",
    "vgg_ip = torch.from_numpy(sl[None, None]).to('cuda')\n",
    "vgg_ip = vgg_ip.repeat(1, 3, 1, 1)\n",
    "vgg_ip = torch.clip(vgg_ip, min=torch.tensor(0.0).to('cuda'), max=vgg_ip.max())\n",
    "print(vgg_ip.min(), vgg_ip.max())\n",
    "\n",
    "vgg_rs = resize(vgg_ip, [224, 224], antialias=False).cpu().numpy()\n",
    "print(vgg_rs.min(), vgg_rs.max())\n",
    "\n",
    "plt.imshow(vgg_rs[0, 0])\n",
    "print(vgg_rs.min(), vgg_rs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e058309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import PIL.Image as Image\n",
    "\n",
    "tf_size_guidance = {\n",
    "    'compressedHistograms': 0,\n",
    "    'images': 65,\n",
    "    'scalars': 0,\n",
    "    'histograms': 0\n",
    "}\n",
    "\n",
    "log_path = '/home/srivathsa/projects/studies/gad/stanford/train/tb/stanford_sri_enh_vgg_1680028723/events.out.tfevents.1680028727.subtle-dgx'\n",
    "event_acc = EventAccumulator(log_path, size_guidance=tf_size_guidance)\n",
    "event_acc.Reload()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d944ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_array(img_bstr):\n",
    "    return np.array(Image.open(io.BytesIO(img_bstr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8350e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = event_acc.Images('Validation_0')\n",
    "im_arr = []\n",
    "for idx, img in enumerate(imgs):\n",
    "    img_bstr = img.encoded_image_string\n",
    "    img = byte_to_array(img_bstr)\n",
    "    im_arr.append(img)\n",
    "im_arr = np.array(im_arr)\n",
    "print(im_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = suio.load_file('/home/srivathsa/projects/studies/gad/tiantan/preprocess/data/NO118.h5').transpose(1, 0, 2, 3)\n",
    "pre, low, full = data\n",
    "\n",
    "print(pre.min(), pre.max())\n",
    "print(low.min(), low.max())\n",
    "print(post.min(), post.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/slices/Patient_0101/ax/234.npy')\n",
    "pre, low, post, enh = data\n",
    "\n",
    "print(pre.min(), pre.max())\n",
    "print(low.min(), low.max())\n",
    "print(post.min(), post.max())\n",
    "print(enh.min(), enh.max())\n",
    "\n",
    "\n",
    "plt.imshow(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e5bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpath = '/home/srivathsa/projects/studies/gad/stanford/preprocess/slices'\n",
    "fp_npys = [fp for fp in glob('{}/**/*.npy'.format(bpath), recursive=True)]\n",
    "\n",
    "nan_cases = []\n",
    "\n",
    "for fp in tqdm(fp_npys, total=len(fp_npys)):\n",
    "    d = np.load(fp)\n",
    "    if d.min() < 0:\n",
    "        cnum = [p for p in fp.split('/') if 'Patient' in p][0]\n",
    "        if cnum not in nan_cases:\n",
    "            nan_cases.append(cnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5158e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp_sub = sorted([fp for fp in fp_npys if 'Patient_0088' in fp])\n",
    "# for fp in fp_sub:\n",
    "#     d = np.load(fp)\n",
    "#     if np.isnan(d.min()) or np.isnan(d.max()):\n",
    "#         print(fp)\n",
    "        \n",
    "# d = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/slices/Patient_0088/ax/002.npy')\n",
    "# plt.imshow(d[-1])\n",
    "\n",
    "print(d[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a599c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/srivathsa/projects/studies/gad/gen_siemens/preprocess/slices/101_Id_007/sag/078.npy')\n",
    "pre, low, post, enh = data\n",
    "\n",
    "print(pre.min(), pre.max())\n",
    "print(low.min(), low.max())\n",
    "print(post.min(), post.max())\n",
    "print(enh.min(), enh.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f016a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ea08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpath = '/home/srivathsa/projects/studies/gad/stanford/preprocess/data'\n",
    "\n",
    "for fpath in glob('{}/*full*'.format(bpath)):\n",
    "    os.rename(fpath, fpath.replace('_full', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack([*data[1, 180]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/mnt/raid/srivathsa/gen_siemens/preprocess/slices/Id0039/ax/140.npy')\n",
    "data[-1] *= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e047152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.hstack([*data]))\n",
    "plt.imshow(data[2] - data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c4202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\n",
    "    '/home/srivathsa/projects/studies/gad/gen_siemens/train/checkpoints/gen_siemens_enh_vgg_1679459081/epoch_184.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\n",
    "    '/home/srivathsa/projects/studies/gad/tiantan/train/checkpoints/tiantan_sri_enh_vgg_1679284107/epoch_199.pth'\n",
    ")\n",
    "print(state_dict['mse'])\n",
    "# iter_num = int(state_dict['opt_G']['state'][0]['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae01851",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = suio.load_file('/home/srivathsa/projects/studies/gad/tiantan/preprocess/data/NO1.h5')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3728b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[160, 1] - data[160, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21306647",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = np.load('/home/srivathsa/projects/studies/gad/tiantan/preprocess/slices/NO1/sag/160.npy')\n",
    "plt.imshow(sl[0, 1] - sl[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4570f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = torch.nn.ReLU(inplace=True)\n",
    "ip = torch.from_numpy(np.array([[1, -2], [-0.5, 3]]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5203ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = relu(ip)\n",
    "print(op, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72456bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = SliceLoader(\n",
    "    data_files=[\n",
    "        '/home/srivathsa/projects/studies/gad/tiantan/preprocess/slices/Brain3H-600437593'\n",
    "    ],\n",
    "    slices_per_input=1,\n",
    "    slice_axis=[2],\n",
    "    resize=240,\n",
    "    use_enh_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a93dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyNS:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 8\n",
    "        self.random_seed = 723\n",
    "args = DummyNS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data_loader.__getitem__(63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack([X[0], X[1], Y[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = X[:7]\n",
    "low = X[7:]\n",
    "\n",
    "# r1 = np.hstack([*pre])\n",
    "# r2 = np.hstack([*low])\n",
    "# diff = np.clip(r2-r1, 0, (r2-r1).max())\n",
    "# img = np.vstack([r2-r1])\n",
    "# plt.imshow(np.hstack([pre[0], low[0], Y[0], Y[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subtle.dnn.generators import GeneratorUNet2D\n",
    "\n",
    "# Xt = torch.from_numpy(X[None].astype(np.float32))\n",
    "net = GeneratorUNet2D(num_channel_input=14, num_channel_output=1).to('cuda')\n",
    "# Y_pred = net(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58015d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dict((p.data_ptr(), p.numel()) for p in net.parameters()).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb86793",
   "metadata": {},
   "source": [
    "### SSIM Loss implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67efbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def extract_image_patches(x, kernel=3, stride=3, dilation=1):\n",
    "    # Do TF 'SAME' Padding\n",
    "    b,c,h,w = x.shape\n",
    "    h2 = math.ceil(h / stride)\n",
    "    w2 = math.ceil(w / stride)\n",
    "    pad_row = (h2 - 1) * stride + (kernel - 1) * dilation + 1 - h\n",
    "    pad_col = (w2 - 1) * stride + (kernel - 1) * dilation + 1 - w\n",
    "    x = F.pad(x, (pad_row//2, pad_row - pad_row//2, pad_col//2, pad_col - pad_col//2))\n",
    "    \n",
    "    # Extract patches\n",
    "    patches = x.unfold(2, kernel, stride).unfold(3, kernel, stride)\n",
    "    patches = patches.permute(0,4,5,1,2,3).contiguous()\n",
    "    \n",
    "    return patches #patches.view(b,-1,patches.shape[-2], patches.shape[-1])\n",
    "\n",
    "def ssim_loss(y_true, y_pred, kernel=(3, 3), k1=.01, k2=.03, kernel_size=3, max_value=1.):\n",
    "    # ssim parameters\n",
    "    cc1 = (k1 * max_value) ** 2\n",
    "    cc2 = (k2 * max_value) ** 2\n",
    "\n",
    "    patches_true = extract_image_patches(y_true)\n",
    "    patches_pred = extract_image_patches(y_pred)\n",
    "    \n",
    "    bs, c1, c2, c3, w, h = patches_pred.shape\n",
    "    patches_true = torch.reshape(patches_true, [-1, c1*c2*c3, w, h])\n",
    "    patches_pred = torch.reshape(patches_pred, [-1, c1*c2*c3, w, h])\n",
    "\n",
    "    # Get mean\n",
    "    u_true = torch.mean(patches_true, dim=1)\n",
    "    u_pred = torch.mean(patches_pred, dim=1)\n",
    "\n",
    "    # Get variance\n",
    "    var_true = torch.var(patches_true, dim=1, unbiased=False)\n",
    "    var_pred = torch.var(patches_pred, dim=1, unbiased=False)\n",
    "\n",
    "    # Get covariance\n",
    "    covar_true_pred = torch.mean(patches_true * patches_pred, dim=1) - (u_true * u_pred)\n",
    "    \n",
    "    # compute ssim and dssim\n",
    "    ssim = (2 * u_true * u_pred + cc1) * (2 * covar_true_pred + cc2)\n",
    "    \n",
    "    denom = (torch.square(u_true) + torch.square(u_pred) + cc1) * (var_pred + var_true + cc2)\n",
    "    ssim /= denom\n",
    "    return torch.mean((1.0 - ssim) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim = ssim_loss(ip1, ip2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = suio.load_file('/home/srivathsa/projects/studies/gad/tiantan/preprocess/data/Case1.h5')\n",
    "\n",
    "pre = data[:, 0]\n",
    "low = data[:, 1]\n",
    "\n",
    "ip1 = torch.from_numpy(pre[98, 8:-8, 8:-8][None, None].astype(np.float32))\n",
    "ip2 = torch.from_numpy(low[98, 8:-8, 8:-8][None, None].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8690ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ssim.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a602845",
   "metadata": {},
   "source": [
    "### VGG-19 Perceptual Loss implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e6d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subtle.subtle_loss import VGGLoss\n",
    "\n",
    "vgg_loss = VGGLoss(fpath_ckp='/home/srivathsa/projects/vgg19_imagenet_from_tf.pth', img_resize=256).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ce3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/slices/Patient_0088/sag/150.npy')\n",
    "data2 = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/slices/Patient_0088/sag/155.npy')\n",
    "\n",
    "pre = data[0]\n",
    "pre2 = data2[0]\n",
    "\n",
    "low = data[1]\n",
    "low2 = data2[1]\n",
    "\n",
    "full = data[2]\n",
    "full2 = data2[2]\n",
    "\n",
    "ip1 = torch.from_numpy(pre[None, None].astype(np.float32)).to('cuda')\n",
    "ip2 = torch.from_numpy(low[None, None].astype(np.float32)).to('cuda')\n",
    "ip3 = torch.from_numpy(full[None, None].astype(np.float32)).to('cuda')\n",
    "ip4 = torch.from_numpy(full2[None, None].astype(np.float32)).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36455d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lval = vgg_loss(ip3, ip4)\n",
    "print(lval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack([full, full2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd64ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sigpy as sp\n",
    "\n",
    "imgnet1 = np.array(Image.open('/home/srivathsa/projects/studies/gad/imagenet1.jpeg'))\n",
    "imgnet1 = sp.util.resize(imgnet1, (224, 224, 3))\n",
    "\n",
    "imgnet2 = np.array(Image.open('/home/srivathsa/projects/studies/gad/imagenet2.jpeg'))\n",
    "imgnet2 = sp.util.resize(imgnet2, (224, 224, 3))\n",
    "\n",
    "print(imgnet1.min(), imgnet1.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fed4b",
   "metadata": {},
   "source": [
    "### General Siemens Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subtle.utils.io as suio\n",
    "\n",
    "data = suio.load_file('/home/srivathsa/projects/studies/gad/gen_siemens/preprocess/data/Prisma14.h5')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43810ee",
   "metadata": {},
   "source": [
    "### Check intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfb3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '/home/srivathsa/projects/studies/gad/tiantan/preprocess/slices'\n",
    "cases = sorted([c.split('/')[-1] for c in glob('{}/*'.format(src_path))])\n",
    "\n",
    "range_info = []\n",
    "\n",
    "planes = ['ax', 'sag', 'cor']\n",
    "\n",
    "for cnum in tqdm(cases, total=len(cases)):\n",
    "    for plane in planes:\n",
    "        fpath_nps = sorted([fp for fp in glob('{}/{}/{}/*.npy'.format(src_path, cnum, plane))])\n",
    "        pre, low, full, mask = np.array([np.load(d) for d in fpath_nps]).transpose(1, 0, 2, 3)\n",
    "#         sl = pre.shape[0] // 2\n",
    "\n",
    "#         row1 = np.hstack([pre[sl], low[sl], full[sl]])\n",
    "#         row2 = np.hstack([low[sl]-pre[sl], full[sl]-pre[sl], mask[sl]])\n",
    "#         img = np.vstack([row1, row2])\n",
    "#         fig, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "#         ax1.imshow(row1)\n",
    "#         ax1.axis('off')\n",
    "\n",
    "#         ax2.imshow(row2)\n",
    "#         ax2.axis('off')\n",
    "\n",
    "#         plt.title(cnum)\n",
    "#         plt.tight_layout(pad=0, w_pad=0, h_pad=0)\n",
    "#         plt.margins(y=0)\n",
    "#         plt.savefig('{}/plots/{}_{}.png'.format(src_path, cnum, plane), dpi=200, bbox_inches='tight')\n",
    "#         plt.clf()\n",
    "#         plt.close()\n",
    "        \n",
    "        range_info.append({\n",
    "            'case': cnum,\n",
    "            'plane': plane,\n",
    "            'pre_min': pre.min(), 'pre_max': pre.max(), 'pre_mean': pre.mean(),\n",
    "            'low_min': low.min(), 'low_max': low.max(), 'low_mean': low.mean(),\n",
    "            'full_min': full.min(), 'full_max': full.max(), 'full_mean': full.mean(),\n",
    "            'mask_min': mask.min(), 'mask_max': mask.max(), 'mask_mean': mask.mean(),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range = pd.DataFrame(range_info)\n",
    "df_range.to_csv('/home/srivathsa/projects/studies/gad/tiantan/preprocess/pytorch_port_range_info_04072023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cases = [\n",
    "    \"Brain2H-600441599\", \"Brain4H-601044594\", \"NO1\", \"NO2\", \"NO3\", \"NO4\", \"NO5\", \"NO7\", \"NO8\", \"NO9\", \"NO10\", \n",
    "    \"NO11\", \"NO12\", \"NO13\", \"NO15\", \"NO16\", \"NO17\", \"NO19\", \"NO20\", \"NO21\", \"NO22\", \"NO23\", \"NO24\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range[[\n",
    "    'case', 'pre_max', 'low_max', 'full_max', 'mask_max', 'plane'\n",
    "]].query('plane == \"cor\" and case in @train_cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51428b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/data/Patient_0126.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e494e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "pre, low, full = data[1].transpose(1, 0, 2, 3)\n",
    "\n",
    "plt.imshow(low[:, 256, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a8a9a",
   "metadata": {},
   "source": [
    "### Inference test and DICOM generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb55df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = SliceLoader(\n",
    "    data_files=[\n",
    "        '/home/srivathsa/projects/studies/gad/stanford/preprocess/slices/Patient_0101'\n",
    "    ],\n",
    "    slices_per_input=7,\n",
    "    slice_axis=[0],\n",
    "    resize=512,\n",
    "    use_enh_mask=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c51feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subtle.dnn.generators import GeneratorUNet2D\n",
    "net = GeneratorUNet2D(num_channel_input=14, num_channel_output=1).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58be57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\n",
    "    '/home/srivathsa/projects/studies/gad/stanford/train/checkpoints/stanford_sri_enh_vgg_1681099486/best_mse.pth',\n",
    "    map_location='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6da205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(state_dict['G'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "768bb973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srivathsa/miniconda3/envs/gad_torch/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed559641e5545cab3c863a3aa75d334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_slices = data_loader.__len__()\n",
    "Y_pred = []\n",
    "for idx in tqdm(np.arange(num_slices), total=num_slices):\n",
    "    X, Y = data_loader.__getitem__(idx)\n",
    "    Xinp = torch.from_numpy(X[None].astype(np.float32)).to('cuda')\n",
    "    Yp = net(Xinp)\n",
    "    Yp = Yp.detach().cpu().numpy()\n",
    "    \n",
    "    Y_pred.append(Yp[0, 0])\n",
    "Y_pred = np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38ee320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.3/itkImageSeriesReader.hxx, line 477\n",
      "ImageSeriesReader (0x558b62e20920): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000144133\n",
      "\n",
      "/home/srivathsa/miniconda3/envs/gad_torch/lib/python3.7/site-packages/pydicom/valuerep.py:290: UserWarning: The value length (19) exceeds the maximum length of 16 allowed for VR DS. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "/home/srivathsa/miniconda3/envs/gad_torch/lib/python3.7/site-packages/pydicom/valuerep.py:290: UserWarning: The value length (18) exceeds the maximum length of 16 allowed for VR DS. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "/home/srivathsa/miniconda3/envs/gad_torch/lib/python3.7/site-packages/pydicom/valuerep.py:290: UserWarning: The value length (17) exceeds the maximum length of 16 allowed for VR DS. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "/home/srivathsa/miniconda3/envs/gad_torch/lib/python3.7/site-packages/pydicom/valuerep.py:290: UserWarning: The value length (20) exceeds the maximum length of 16 allowed for VR DS. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "ip_dcm = '/home/srivathsa/projects/studies/gad/stanford/data/Patient_0101/13_Ax_BRAVO+C'\n",
    "ip_sitk = dcm_to_sitk(ip_dcm)\n",
    "ref_arr = sitk.GetArrayFromImage(ip_sitk)\n",
    "\n",
    "sc = ref_arr.max() / Y_pred.max()\n",
    "\n",
    "prefix = 'SubtleGAD pyt: '\n",
    "desc = 'enh_vgg_v2'\n",
    "suffix = ''\n",
    "\n",
    "Y_pred = np.clip(Y_pred, 0, Y_pred.max())\n",
    "Y_pred = Y_pred * sc\n",
    "suio.write_dicoms(\n",
    "    ip_dcm, Y_pred, '/home/srivathsa/projects/studies/gad/stanford/data/pyt_test/Patient_0101_pyt_{}'.format(desc),\n",
    "    series_desc_pre=prefix, desc=desc, series_desc_post=suffix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred.min(), Y_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range = pd.read_csv(\n",
    "    '/home/srivathsa/projects/studies/gad/stanford/preprocess/pytorch_port_range_info_04052023.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074b37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51465b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range[[\n",
    "    'case', 'mask_min', 'mask_max', 'plane'\n",
    "]].query('plane == \"ax\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a970ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath_exp = '/home/srivathsa/projects/SubtleGad/train/configs/experiments'\n",
    "cases = get_experiment_data('tiantan_sri', dataset='train', dirpath_exp=dpath_exp)\n",
    "cases = cases + get_experiment_data('tiantan_sri', dataset='val', dirpath_exp=dpath_exp)\n",
    "src_path = '/home/srivathsa/projects/studies/gad/tiantan/preprocess/slices'\n",
    "dest_path = '/home/srivathsa/projects/studies/gad/tiantan/preprocess/slices/accio_train'\n",
    "\n",
    "for cnum in cases:\n",
    "    shutil.copytree('{}/{}'.format(src_path, cnum), '{}/{}'.format(dest_path, cnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ce635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gad_torch)",
   "language": "python",
   "name": "gad_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
