{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import QC\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "def get_qc_score_dict(results_gt, results_gad, dir_paths):\n",
    "    rdict = []\n",
    "    for i, df_result in enumerate(results_gt):\n",
    "        gt_score_arr = np.array(df_result[0])\n",
    "        gad_score_arr = np.array(results_gad[i][0])\n",
    "        sl_idx = int(gt_score_arr.shape[0] * 0.2)\n",
    "        gt_score = 1 - gt_score_arr[sl_idx:-sl_idx].mean()\n",
    "        gad_score = 1 - gad_score_arr[sl_idx:-sl_idx].mean()\n",
    "        rdict.append({\n",
    "            'case': dir_paths[i].split('/')[-1],\n",
    "            'gt_score': gt_score,\n",
    "            'gad_score': gad_score,\n",
    "            'error_rate': ((gad_score - gt_score) / gad_score)*100\n",
    "        })\n",
    "    return rdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/srivathsa/projects/studies/gad/stanford/data/0bb433_3f27a5'\n",
    "gt_path = '/home/srivathsa/projects/studies/gad/stanford/data'\n",
    "dir_paths = [d for d in glob('{}/*'.format(base_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'batches_per_queue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-efc7ae6d0ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_gad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/QualityControl/QC/QCapp/utils.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(input_data, augmentation_steps)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     data_generator = make_data_generator(data_list=input_data,preproc_params=cfg['preprocessing'],\n\u001b[0;32m---> 74\u001b[0;31m                                          dim_to_sample=0,augmentation_steps=augmentation_steps)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mout_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextsep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/QualityControl/QC/QCapp/utils.py\u001b[0m in \u001b[0;36mmake_data_generator\u001b[0;34m(data_list, preproc_params, dim_to_sample, augmentation_steps)\u001b[0m\n\u001b[1;32m     50\u001b[0m     data_gen = MultipleImageSliceGenerator(data_list, img_size=preproc_params['output_shape'],\n\u001b[1;32m     51\u001b[0m                              \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocessing_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessing_pipeline_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                              dims_to_sample=[int(dim_to_sample)],dtype='float32')\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/QualityControl/QC/util/io.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultipleImageSliceGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'batches_per_queue'"
     ]
    }
   ],
   "source": [
    "results_gad = QC.predict(dir_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt_dirs = []\n",
    "\n",
    "sort_fn = lambda d: int(d.split('/')[-1].split('_')[0])\n",
    "for d in dir_paths:\n",
    "    gt_dir = '{}/{}'.format(gt_path, d.split('/')[-1])\n",
    "    sub_dirs = sorted([sdir for sdir in glob('{}/*'.format(gt_dir))], key=lambda d: int(d.split('/')[-1].split('_')[0]))\n",
    "    gt_dirs.append(sub_dirs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting 0 of 173\n",
      "predicting 1 of 173\n",
      "predicting 2 of 173\n",
      "predicting 3 of 173\n",
      "predicting 4 of 173\n",
      "predicting 5 of 173\n",
      "predicting 6 of 173\n",
      "predicting 7 of 173\n",
      "predicting 8 of 173\n",
      "predicting 9 of 173\n",
      "predicting 10 of 173\n",
      "predicting 11 of 173\n",
      "predicting 12 of 173\n",
      "predicting 13 of 173\n",
      "predicting 14 of 173\n",
      "predicting 15 of 173\n",
      "predicting 16 of 173\n",
      "predicting 17 of 173\n",
      "predicting 18 of 173\n",
      "predicting 19 of 173\n",
      "predicting 20 of 173\n",
      "predicting 21 of 173\n",
      "predicting 22 of 173\n",
      "predicting 23 of 173\n",
      "predicting 24 of 173\n",
      "predicting 25 of 173\n",
      "predicting 26 of 173\n",
      "predicting 27 of 173\n",
      "predicting 28 of 173\n",
      "predicting 29 of 173\n",
      "predicting 30 of 173\n",
      "predicting 31 of 173\n",
      "predicting 32 of 173\n",
      "predicting 33 of 173\n",
      "predicting 34 of 173\n",
      "predicting 35 of 173\n",
      "predicting 36 of 173\n",
      "predicting 37 of 173\n",
      "predicting 38 of 173\n",
      "predicting 39 of 173\n",
      "predicting 40 of 173\n",
      "predicting 41 of 173\n",
      "predicting 42 of 173\n",
      "predicting 43 of 173\n",
      "predicting 44 of 173\n",
      "predicting 45 of 173\n",
      "predicting 46 of 173\n",
      "predicting 47 of 173\n",
      "predicting 48 of 173\n",
      "predicting 49 of 173\n",
      "predicting 50 of 173\n",
      "predicting 51 of 173\n",
      "predicting 52 of 173\n",
      "predicting 53 of 173\n",
      "predicting 54 of 173\n",
      "predicting 55 of 173\n",
      "predicting 56 of 173\n",
      "predicting 57 of 173\n",
      "predicting 58 of 173\n",
      "predicting 59 of 173\n",
      "predicting 60 of 173\n",
      "predicting 61 of 173\n",
      "predicting 62 of 173\n",
      "predicting 63 of 173\n",
      "predicting 64 of 173\n",
      "predicting 65 of 173\n",
      "predicting 66 of 173\n",
      "predicting 67 of 173\n",
      "predicting 68 of 173\n",
      "predicting 69 of 173\n",
      "predicting 70 of 173\n",
      "predicting 71 of 173\n",
      "predicting 72 of 173\n",
      "predicting 73 of 173\n",
      "predicting 74 of 173\n",
      "predicting 75 of 173\n",
      "predicting 76 of 173\n",
      "predicting 77 of 173\n",
      "predicting 78 of 173\n",
      "predicting 79 of 173\n",
      "predicting 80 of 173\n",
      "predicting 81 of 173\n",
      "predicting 82 of 173\n",
      "predicting 83 of 173\n",
      "predicting 84 of 173\n",
      "predicting 85 of 173\n",
      "predicting 86 of 173\n",
      "predicting 87 of 173\n",
      "predicting 88 of 173\n",
      "predicting 89 of 173\n",
      "predicting 90 of 173\n",
      "predicting 91 of 173\n",
      "predicting 92 of 173\n",
      "predicting 93 of 173\n",
      "predicting 94 of 173\n",
      "predicting 95 of 173\n",
      "predicting 96 of 173\n",
      "predicting 97 of 173\n",
      "predicting 98 of 173\n",
      "predicting 99 of 173\n",
      "predicting 100 of 173\n",
      "predicting 101 of 173\n",
      "predicting 102 of 173\n",
      "predicting 103 of 173\n",
      "predicting 104 of 173\n",
      "predicting 105 of 173\n",
      "predicting 106 of 173\n",
      "predicting 107 of 173\n",
      "predicting 108 of 173\n",
      "predicting 109 of 173\n",
      "predicting 110 of 173\n",
      "predicting 111 of 173\n",
      "predicting 112 of 173\n",
      "predicting 113 of 173\n",
      "predicting 114 of 173\n",
      "predicting 115 of 173\n",
      "predicting 116 of 173\n",
      "predicting 117 of 173\n",
      "predicting 118 of 173\n",
      "predicting 119 of 173\n",
      "predicting 120 of 173\n",
      "predicting 121 of 173\n",
      "predicting 122 of 173\n",
      "predicting 123 of 173\n",
      "predicting 124 of 173\n",
      "predicting 125 of 173\n",
      "predicting 126 of 173\n",
      "predicting 127 of 173\n",
      "predicting 128 of 173\n",
      "predicting 129 of 173\n",
      "predicting 130 of 173\n",
      "predicting 131 of 173\n",
      "predicting 132 of 173\n",
      "predicting 133 of 173\n",
      "predicting 134 of 173\n",
      "predicting 135 of 173\n",
      "predicting 136 of 173\n",
      "predicting 137 of 173\n",
      "predicting 138 of 173\n",
      "predicting 139 of 173\n",
      "predicting 140 of 173\n",
      "predicting 141 of 173\n",
      "predicting 142 of 173\n",
      "predicting 143 of 173\n",
      "predicting 144 of 173\n",
      "predicting 145 of 173\n",
      "predicting 146 of 173\n",
      "predicting 147 of 173\n",
      "predicting 148 of 173\n",
      "predicting 149 of 173\n",
      "predicting 150 of 173\n",
      "predicting 151 of 173\n",
      "predicting 152 of 173\n",
      "predicting 153 of 173\n",
      "predicting 154 of 173\n",
      "predicting 155 of 173\n",
      "predicting 156 of 173\n",
      "predicting 157 of 173\n",
      "predicting 158 of 173\n",
      "predicting 159 of 173\n",
      "predicting 160 of 173\n",
      "predicting 161 of 173\n",
      "predicting 162 of 173\n",
      "predicting 163 of 173\n",
      "predicting 164 of 173\n",
      "predicting 165 of 173\n",
      "predicting 166 of 173\n",
      "predicting 167 of 173\n",
      "predicting 168 of 173\n",
      "predicting 169 of 173\n",
      "predicting 170 of 173\n",
      "predicting 171 of 173\n",
      "predicting 172 of 173\n"
     ]
    }
   ],
   "source": [
    "results_gt = QC.predict(gt_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdict = get_qc_score_dict(results_gt, results_gad, dir_paths)\n",
    "df_results = pd.DataFrame(rdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.119308742991688"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df_results['error_rate']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36torch)",
   "language": "python",
   "name": "py36torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
