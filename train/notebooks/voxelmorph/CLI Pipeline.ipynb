{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa71296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from glob import glob\n",
    "from scipy.ndimage import affine_transform\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('gray')\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "from subtle.subtle_preprocess import (\n",
    "    dcm_to_sitk, _get_crop_range, normalize_im, scale_im_enhao, apply_reg_transform, register_im\n",
    ")\n",
    "from subtle_utils.dcmutil.pydicom_utils import get_image_orientation\n",
    "from voxelmorph.tf.networks import VxmAffine, AIRNet, Transform\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def get_dcm_from_dir(dpath_dcm):\n",
    "    dcm_files = sorted([f for f in glob('{}/**/*'.format(dpath_dcm), recursive=True) if os.path.isfile(f)])\n",
    "    return pydicom.dcmread(dcm_files[0])\n",
    "\n",
    "def crop_or_pad(img, ref_img):\n",
    "    if img.shape == ref_img.shape:\n",
    "        return img\n",
    "    pad_args = {'mode': 'constant', 'constant_values': 0}\n",
    "    \n",
    "    crop_arr = []\n",
    "    pad_arr = []\n",
    "    for sh_idx in np.arange(img.ndim):\n",
    "        sh_diff = img.shape[sh_idx] - ref_img.shape[sh_idx]\n",
    "        \n",
    "        if sh_diff == 0:\n",
    "            crop_arr.append('none')\n",
    "            pad_arr.append((0, 0))\n",
    "        elif sh_diff < 0:\n",
    "            sh_diff = np.abs(sh_diff)\n",
    "            d1 = sh_diff // 2\n",
    "            d2 = d1 if sh_diff % 2 == 0 else d1 + 1\n",
    "\n",
    "            crop_arr.append('none')\n",
    "            pad_arr.append((d1, d2))\n",
    "        else:\n",
    "            if sh_diff == 1:\n",
    "                s = 0\n",
    "                e = img.shape[sh_idx] - 1\n",
    "            else:\n",
    "                s, _e = _get_crop_range(sh_diff)\n",
    "                e = img.shape[sh_idx] - _e\n",
    "            arg = (s, e)\n",
    "            \n",
    "            crop_arr.append((s, e))\n",
    "            pad_arr.append((0, 0))\n",
    "    \n",
    "    pad_args['pad_width'] = pad_arr\n",
    "    out_img = np.pad(img, **pad_args)\n",
    "    \n",
    "    for i, crop_info in enumerate(crop_arr):\n",
    "        if crop_info == 'none': continue\n",
    "        out_img = np.take(out_img, np.arange(crop_info[0], crop_info[1]), axis=i)\n",
    "    \n",
    "    return out_img\n",
    "\n",
    "def intensity_scale(img):\n",
    "    img = normalize_im(img, axis=(1, 2))\n",
    "    img = np.interp(img, (img.min(), img.max()), (0, 1))\n",
    "    return img\n",
    "\n",
    "def get_aff_model(model, fpath_ckp):\n",
    "    aff_layer = model.model.get_layer('{}_aff_mtx'.format(model.name))\n",
    "    aff_model = Model(\n",
    "        inputs=[model.model.layers[0].input, model.model.layers[1].input], \n",
    "        outputs=aff_layer.output\n",
    "    )\n",
    "    aff_model.load_weights(fpath_ckp, by_name=True)\n",
    "    return aff_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0dadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpath_fx = '/home/srivathsa/projects/studies/gad/tiantan/data/NO30/3DT1WMPRAGE_SAG_CS4_301'\n",
    "# dpath_mv = '/home/srivathsa/projects/studies/gad/tiantan/data/NO30/T2W_NEW_TRA_Series0201'\n",
    "\n",
    "dpath_fx = '/home/srivathsa/projects/studies/gad/stanford/data/Patient_0125/7_AX_BRAVO_PRE'\n",
    "dpath_mv = '/home/srivathsa/projects/studies/gad/stanford/data/Patient_0125/10_AX_BRAVO_+C'\n",
    "\n",
    "dpath_ckp = '/home/srivathsa/projects/studies/gad/vmorph/best_ckps'\n",
    "fx_con = 't1'\n",
    "mv_con = 't2'\n",
    "\n",
    "mdl_specs = {\n",
    "    't1': {\n",
    "        'inshape': (128, 256, 256),\n",
    "        'ckp_name': '20220413_220425-brats_real_t1.h5',\n",
    "        'model': VxmAffine\n",
    "    },\n",
    "    't2': {\n",
    "        'inshape': (128, 240, 240),\n",
    "        'ckp_name': '20211013_004451-brats_t2.h5',\n",
    "        'model': AIRNet\n",
    "    },\n",
    "    'fl': {\n",
    "        'inshape': (128, 240, 240),\n",
    "        'ckp_name': '20211012_050145-brats_fl.h5',\n",
    "        'model': AIRNet\n",
    "    }\n",
    "}\n",
    "\n",
    "spec_obj = mdl_specs[mv_con]\n",
    "mdl_z, mdl_x, mdl_y = spec_obj['inshape']\n",
    "\n",
    "mdl_spacing = (1, 1, 1)\n",
    "\n",
    "fx = dcm_to_sitk(dpath_fx)\n",
    "mv = dcm_to_sitk(dpath_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample moving image to fixed image space\n",
    "mv_rs = sitk.Resample(mv, fx.GetSize(), sitk.Transform(), sitk.sitkNearestNeighbor, fx.GetOrigin(), \n",
    "                          fx.GetSpacing(), fx.GetDirection(), 0, mv.GetPixelID())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_out = int(np.ceil(fx.GetSize()[-1] * (fx.GetSpacing()[-1] / mdl_spacing[-1])))\n",
    "\n",
    "# resample fixed image to model size\n",
    "fx_rs_mdl = sitk.Resample(fx, (mdl_x, mdl_y, z_out), sitk.Transform(), sitk.sitkNearestNeighbor, \n",
    "                          fx.GetOrigin(), mdl_spacing, fx.GetDirection(), 0, fx.GetPixelID())\n",
    "\n",
    "# resample moving image (already resampled to fixed space) to model size\n",
    "mv_rs_mdl = sitk.Resample(mv_rs, (mdl_x, mdl_y, z_out), sitk.Transform(), sitk.sitkNearestNeighbor, \n",
    "                          mv_rs.GetOrigin(), mdl_spacing, mv_rs.GetDirection(), 0, mv_rs.GetPixelID())\n",
    "\n",
    "# adjust the slice dimension according to model specs\n",
    "mdl_ref = np.zeros((mdl_z, mdl_x, mdl_y))\n",
    "\n",
    "fx_np = sitk.GetArrayFromImage(fx_rs_mdl)\n",
    "mv_np = sitk.GetArrayFromImage(mv_rs_mdl)\n",
    "\n",
    "fx_np = crop_or_pad(fx_np, mdl_ref)\n",
    "mv_np = crop_or_pad(mv_np, mdl_ref)\n",
    "\n",
    "fx_np = intensity_scale(fx_np)[None, ..., None]\n",
    "mv_np = intensity_scale(mv_np)[None, ..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'inshape': (mdl_z, mdl_x, mdl_y),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "if 'VxmAffine' in str(spec_obj['model']):\n",
    "    ext_config = {\n",
    "        'batch_norm': False,\n",
    "        'constraint_params': False,\n",
    "        'enc_only': False\n",
    "    }\n",
    "    \n",
    "    model_config = {**model_config, **ext_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model = spec_obj['model'](**model_config)\n",
    "t1 = time()\n",
    "aff_model = get_aff_model(img_model, fpath_ckp=os.path.join(dpath_ckp, spec_obj['ckp_name']))\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_obj['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b405e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "aff_params = aff_model.predict([mv_np, fx_np])[0]\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_rs_np = sitk.GetArrayFromImage(mv_rs)\n",
    "# t1 = time()\n",
    "# moved = affine_transform(mv_rs_np, aff_params)\n",
    "# t2 = time()\n",
    "# print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Transform(inshape=mv_rs_np.shape, affine=True)\n",
    "t1 = time()\n",
    "moved = tfm.predict([mv_rs_np[None, ..., None], aff_params[None]])[0, ..., 0]\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c8b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voxelmorph",
   "language": "python",
   "name": "voxelmorph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
