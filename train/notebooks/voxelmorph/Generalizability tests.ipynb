{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac37fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import yaml\n",
    "from scipy.ndimage import affine_transform\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.set_cmap('gray')\n",
    "\n",
    "from voxelmorph.tf.networks import AIRNet, Transform, VxmAffine\n",
    "from scripts.tf import eval as quant_eval\n",
    "from voxelmorph.tf.utils import params_to_affine_matrix\n",
    "import subtle.subtle_metrics as su_metrics\n",
    "\n",
    "def process_brats_vol(img_vol, pad=False, is_seg=False):\n",
    "    img_vol = np.rot90(img_vol.transpose(2, 0, 1), axes=(1, 2), k=3)\n",
    "    img_vol = img_vol[13:-14]\n",
    "    \n",
    "    if not is_seg:\n",
    "        img_vol = img_vol / img_vol.mean()\n",
    "        img_vol = np.interp(img_vol, (img_vol.min(), img_vol.max()), (0, 1))\n",
    "    \n",
    "    if pad:\n",
    "        img_vol = np.pad(img_vol, pad_width=[(0, 0), (8, 8), (8, 8)], mode='constant', constant_values=0)\n",
    "    return img_vol\n",
    "\n",
    "def get_best_ckp(exp_path, exp_id):\n",
    "    print('Fetching best checkpoint file for {}...'.format(exp_id))\n",
    "    fpath_ckps = sorted([f for f in glob('{}/{}/ckps/*.h5'.format(exp_path, exp_id))])\n",
    "    last_ckp_num = int(fpath_ckps[-1].split('/')[-1].replace('.h5', ''))\n",
    "    num_ckps = last_ckp_num // 5\n",
    "    step_idxs = [i-1 for i in np.arange(5, last_ckp_num + 1, 5)]\n",
    "    \n",
    "    log_path = '{}/{}/logs/tb'.format(exp_path, exp_id)\n",
    "    num_files = len(glob('{}/*'.format(log_path)))\n",
    "\n",
    "    tf_size_guidance = {\n",
    "        'compressedHistograms': 0,\n",
    "        'images': num_files,\n",
    "        'scalars': last_ckp_num+1,\n",
    "        'histograms': 0\n",
    "    }\n",
    "\n",
    "    event_acc = EventAccumulator(log_path, size_guidance=tf_size_guidance)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    \n",
    "    val_losses = [(v.step, v.value) for v in event_acc.Scalars('val_loss') if v.step in step_idxs]\n",
    "    min_idx = np.argmin([v[1] for v in val_losses])\n",
    "    \n",
    "    ep_idx = (val_losses[min_idx][0] + 1)\n",
    "    fpath_ckp = '{exp_path}/{exp_id}/ckps/{epoch:04d}.h5'.format(exp_path=exp_path, exp_id=exp_id, epoch=ep_idx)\n",
    "    \n",
    "    return fpath_ckp, ep_idx\n",
    "    \n",
    "def fetch_eval_models(exp_path, exp_id, tfm_models=True):\n",
    "    exp_dir = os.path.join(exp_path, exp_id)\n",
    "    config = yaml.load(open('{}/config.yaml'.format(exp_dir), 'r').read())\n",
    "    model_dict = {\n",
    "        'airnet': AIRNet,\n",
    "        'affine': VxmAffine\n",
    "    }\n",
    "\n",
    "    img_list = open(config['img_list'], 'r').read().split('\\n')\n",
    "    sample_data = np.load(img_list[0])['data']\n",
    "    img_shape = sample_data.shape[1:]\n",
    "\n",
    "    arch = config['arch']\n",
    "    model_params = {\n",
    "        'inshape': img_shape,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    if arch == 'affine':\n",
    "        model_params['batch_norm'] = (config['bnorm'] == 'true')\n",
    "        model_params['constraint_params'] = (config['constraint_params'] == 'true')\n",
    "        model_params['enc_only'] = (config['network_mode'] == 'enc')\n",
    "    print('MODEL PARAMS', model_params)\n",
    "    eval_model = model_dict[arch](**model_params)\n",
    "    \n",
    "    if tfm_models:\n",
    "        tfm_model_gt = Transform(inshape=img_shape, affine=True, shift_center=False)\n",
    "        tfm_model_pred = Transform(inshape=img_shape, affine=True)\n",
    "        return eval_model, tfm_model_gt, tfm_model_pred\n",
    "    return eval_model\n",
    "        \n",
    "    \n",
    "def get_model_pred(model, aff_model, fixed, moving):\n",
    "    ip1 = fixed[None, ..., None]\n",
    "    ip2 = moving[None, ..., None]\n",
    "    \n",
    "    pred_img = model.model.predict([ip2, ip1])[0, ..., 0]\n",
    "    pred_aff = aff_model.predict([ip2, ip1])[0]\n",
    "    return pred_img, pred_aff\n",
    "\n",
    "def get_aff_model(model, fpath_ckp):\n",
    "    aff_layer = model.model.get_layer('{}_aff_mtx'.format(model.name))\n",
    "    aff_model = Model(\n",
    "        inputs=[model.model.layers[0].input, model.model.layers[1].input], \n",
    "        outputs=aff_layer.output\n",
    "    )\n",
    "    aff_model.load_weights(fpath_ckp, by_name=True)\n",
    "    return aff_model\n",
    "\n",
    "def get_seg_mask(fpath_ref, cnum, pad_ref):\n",
    "    seg_gt = process_brats_vol(\n",
    "        nib.load('{}/{}/{}_seg.nii.gz'.format(fpath_ref, cnum, cnum)).get_fdata(), is_seg=True, pad=pad_ref\n",
    "    )\n",
    "    seg_gt = (seg_gt > 0).astype(np.uint8) #combine all tumor classes into one mask\n",
    "    return seg_gt\n",
    "\n",
    "def compute_dice(seg_gt, aff_sim, aff_pred, pad_ref, tfm_models):\n",
    "    seg_sim = tfm_models[0].predict([seg_gt[None, ..., None], aff_sim[None]])[0, ..., 0]\n",
    "    seg_sim = (seg_sim > 0.9).astype(np.uint8)\n",
    "    \n",
    "    seg_pred = tfm_models[1].predict([seg_sim[None, ..., None], aff_pred[None]])[0, ..., 0]\n",
    "    seg_pred = (seg_pred > 0.9).astype(np.uint8)\n",
    "    \n",
    "    dice = su_metrics.dice(seg_gt, seg_pred)\n",
    "    return dice\n",
    "\n",
    "def compute_incremental_variation(data_path, exp_path, exp_id, fpath_ref, case_num, \n",
    "                                  aff_type='translation', aff_axis='x', aff_array=None):\n",
    "    t1pre, t1post = np.load('{}/{}.npz'.format(data_path, case_num))['data']\n",
    "\n",
    "    fpath_ckp, _ = get_best_ckp(exp_path, exp_id)\n",
    "    model, tfm_model_gt, tfm_model_pred = fetch_eval_models(exp_path, exp_id)\n",
    "    model.model.load_weights(fpath_ckp)\n",
    "    aff_model = get_aff_model(model, fpath_ckp)\n",
    "\n",
    "    seg_gt = get_seg_mask(fpath_ref, case_num, pad_ref=True)\n",
    "\n",
    "    tfm_model_seg1 = Transform(\n",
    "        inshape=tuple(t1pre.shape), affine=True, interp_method='nearest', shift_center=False\n",
    "    )\n",
    "\n",
    "    tfm_model_seg2 = Transform(\n",
    "        inshape=tuple(t1pre.shape), affine=True, interp_method='nearest', shift_center=True\n",
    "    )\n",
    "\n",
    "    tfm_models = [tfm_model_seg1, tfm_model_seg2]\n",
    "    \n",
    "    if aff_array is None:\n",
    "        aff_array = np.arange(0, 20, 0.5).astype(np.float32)\n",
    "    \n",
    "    dir_plot = os.path.join(exp_path, exp_id, 'eval', 'plots', '{}_{}'.format(aff_type, aff_axis), case_num)\n",
    "    if not os.path.exists(dir_plot):\n",
    "        os.makedirs(dir_plot)\n",
    "    \n",
    "    if aff_type == 'translation':\n",
    "        idx_map = {'x': 2, 'y': 1, 'z': 0}\n",
    "        aff_shift = np.array([0.0] * 3)\n",
    "    elif aff_type == 'rotation':\n",
    "        idx_map = {'xy': 5, 'xz': 4, 'yz': 3}\n",
    "        aff_shift = np.array([0.0] * 6)\n",
    "    else:\n",
    "        raise ValueError('Affine type must be translation or rotation')\n",
    "    \n",
    "    metric_list = []\n",
    "    for i, aval in enumerate(tqdm(aff_array, total=len(aff_array))):\n",
    "        aff_shift[idx_map[aff_axis]] = aval\n",
    "        aff = K.eval(params_to_affine_matrix(aff_shift))\n",
    "\n",
    "        moving = affine_transform(t1post, aff)\n",
    "        moving = np.clip(moving, 0, moving.max())\n",
    "\n",
    "        pred, aff_pred = get_model_pred(model, aff_model, t1pre, moving)\n",
    "        dice = compute_dice(seg_gt, aff, aff_pred, pad_ref=True, tfm_models=tfm_models)\n",
    "\n",
    "        plt.imshow(np.hstack([moving[64] - t1pre[64], pred[64] - t1pre[64]]))\n",
    "        plt.title('X Shift = {:.3f}, Dice = {:.3f}'.format(aval, dice))\n",
    "        plt.savefig('{}/Img_{}.png'.format(dir_plot, i))\n",
    "        plt.clf()\n",
    "        \n",
    "        metric_obj = {'aff_val': aval, 'dice': dice}\n",
    "        metric_list.append(metric_obj)\n",
    "    \n",
    "    pd.DataFrame(metric_list).to_csv('{}/scores.csv'.format(dir_plot))\n",
    "\n",
    "def eval_model_variation(data_path, exp_path, exp_id, fpath_ref, num_cases=25):\n",
    "    all_cases = [f.split('/')[-1].replace('.npz', '') for f in glob('{}/*.npz'.format(data_path))]\n",
    "    case_nums = np.random.choice(all_cases, size=num_cases, replace=False)\n",
    "    \n",
    "    aff_types = ['translation', 'rotation']\n",
    "    aff_axes = [['x', 'y', 'z'], ['xy' 'xz', 'yz']]\n",
    "    aff_arrs = [np.arange(0, 20, 1), np.arange(0, 15, 0.75)]\n",
    "    \n",
    "    for a_idx, aff_type in enumerate(aff_types):\n",
    "        aff_axis = aff_axes[a_idx]\n",
    "        aff_array = aff_arrs[a_idx]\n",
    "        \n",
    "        for ax in aff_axis:\n",
    "            print('Computing variation in {} axis for {}...'.format(ax, aff_type))\n",
    "            \n",
    "            for case_num in case_nums:\n",
    "                compute_incremental_variation(data_path, exp_path, exp_id, fpath_ref, \n",
    "                                              case_num, aff_type, aff_axis=ax, aff_array=aff_array)\n",
    "def sag2ax(img_vol):\n",
    "    img_vol = img_vol.transpose(2, 1, 0)\n",
    "    img_vol = np.rot90(img_vol, axes=(1, 2), k=1)[64:-64]\n",
    "    img_vol = np.pad(img_vol, [(0, 0), (64, 64), (0, 0)])\n",
    "    img_vol = np.clip(img_vol, 0, img_vol.max())\n",
    "    return img_vol\n",
    "\n",
    "def plot_pred(fixed, moving, reg, fpath=None, ref_prereg=None, sl=None):\n",
    "    sl_idx = sl if sl is not None else fixed.shape[0] // 2\n",
    "    img1 = np.hstack([fixed[sl_idx], moving[sl_idx], reg[sl_idx]])\n",
    "    \n",
    "    diff1 = moving - fixed\n",
    "    diff2 = reg - fixed\n",
    "    diff3 = np.zeros_like(fixed)\n",
    "    if ref_prereg is not None:\n",
    "        diff3 = ref_prereg - fixed\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 3)\n",
    "    \n",
    "    imgs = [\n",
    "        (fixed[sl_idx], 'Fixed'), \n",
    "        (moving[sl_idx], 'Moving'), \n",
    "        (reg[sl_idx], 'Registered'), \n",
    "        (diff1[sl_idx], 'Diff(fixed, moving)'), \n",
    "        (diff2[sl_idx], 'Diff(fixed, registered)'),\n",
    "        (diff3[sl_idx], 'Diff - BRATS prereg')\n",
    "    ]\n",
    "    k = 0\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            axs[i, j].imshow(imgs[k][0])\n",
    "            axs[i, j].axis('off')\n",
    "            axs[i, j].set_title(imgs[k][1])\n",
    "            k += 1\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if fpath:\n",
    "        plt.savefig(fpath)\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = '/home/srivathsa/projects/studies/gad/vmorph/runs'\n",
    "exp_id = '20211018_212059-brats'\n",
    "data_path = '/home/srivathsa/projects/studies/gad/vmorph/data/sford_post_nobet/val'\n",
    "\n",
    "model = fetch_eval_models(exp_path, exp_id, tfm_models=False)\n",
    "fpath_ckp, _ = get_best_ckp(exp_path, exp_id)\n",
    "model.model.load_weights(fpath_ckp)\n",
    "aff_model = get_aff_model(model, fpath_ckp)\n",
    "\n",
    "cases = sorted([f.split('/')[-1].replace('.npz', '') for f in glob('{}/*.npz'.format(data_path))])\n",
    "dirpath_plot = '/home/srivathsa/projects/studies/gad/vmorph/sford_eval/{}_{}'.format(exp_id, data_path.split('/')[-2])\n",
    "if not os.path.exists(dirpath_plot):\n",
    "    os.makedirs(dirpath_plot)\n",
    "\n",
    "for case_num in tqdm(cases, total=len(cases)):\n",
    "    fixed, moving = np.load('{}/{}.npz'.format(data_path, case_num))['data']\n",
    "    \n",
    "#     fixed = np.clip(fixed, 0, fixed.max())\n",
    "#     moving = np.clip(moving, 0, moving.max())\n",
    "    \n",
    "    pred, aff = get_model_pred(model, aff_model, fixed, moving)\n",
    "    fpath_plot = '{}/{}.png'.format(dirpath_plot, case_num)\n",
    "    plot_pred(fixed, moving, pred, fpath_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/srivathsa/projects/studies/gad/vmorph/data/sford_post/val/Patient_0149.npz')['data']\n",
    "\n",
    "plt.imshow(np.hstack([data[0, 64], data[1, 64]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9aa4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voxelmorph",
   "language": "python",
   "name": "voxelmorph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
