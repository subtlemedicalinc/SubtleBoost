{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3D general patch from T2\n",
    "\n",
    "# background info\n",
    "# For T2, we used 1. mean \\in (0.2*max(image), 0.6*max(img)) 2. diff \n",
    "\n",
    "# guideline\n",
    "# - use the axial axis for the 3d volume\n",
    "# - check the first and last slice from the volume\n",
    "# - apply mean and diff \n",
    "# - use AND for the two slices\n",
    "# - zoomed\n",
    "\n",
    "# questions:\n",
    "# - do we save enough patch using the strategy above?  Wait for the current training\n",
    "# - do we need to filter all slice within the volume?  No\n",
    "# - do the criteria for T2 apply for the T1 cases? Yes\n",
    "\n",
    "# func: \n",
    "# input: numpy array after pre-processing \n",
    "# output: hdf5 files\n",
    "\n",
    "# procedures:\n",
    "# - select one case (101_Id_013) => with motion, \n",
    "# - save the slice location for each patch (axial axis)\n",
    "# - calculate the max for each slice(image-based)\n",
    "# - filter the first and the last patch\n",
    "# - apply AND\n",
    "# - saved as hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/subtle/Long/SubtleMR/src/utils\")\n",
    "from co_registration import extract_info, register_im\n",
    "from others import pad_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util.shape import view_as_windows\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract patch\n",
    "def filter_3d(norm_low, norm_high, patch_size, step, thresh_low_ratio, thresh_high_ratio,\n",
    "              thresh_diff_ratio, channel, verbose):\n",
    "    \"\"\"\n",
    "    generate a set of 3d patch that could be used for training\n",
    "    \n",
    "    args:\n",
    "    -------\n",
    "    norm_low: the original volume for the lowres (after pre-processing)\n",
    "    norm_high: the original volume for the highres (after pre-processing)\n",
    "    patch_size: the patch size for the 3d patch volume (int)\n",
    "    step: steps (int)\n",
    "    thresh_low_ratio: a ratio used to filter out the background area\n",
    "    thresh_diff_ratio: a ratio used to filter out the large intensity difference\n",
    "    verbose: verbose mode\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    saved_patch_ins: 3d low-res patches for training\n",
    "    saved_patch_outs: 3d high-res patches for training\n",
    "    \"\"\"\n",
    "    # calculate norm_max\n",
    "    norm_slice_max = np.max(norm_low, axis=tuple(x for x in (0, 1, 2) if x != channel))\n",
    "    \n",
    "    # set up the patch\n",
    "    norm_patch_ins = view_as_windows(norm_low, window_shape=patch_size, step=step)\n",
    "    norm_patch_outs = view_as_windows(norm_high, window_shape=patch_size, step=step)\n",
    "    nrow, ncol, nchan = norm_patch_ins.shape[:3]\n",
    "\n",
    "    saved_patch_ins, saved_patch_outs = [], []\n",
    "    # go thru each patch volume\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            for k in range(nchan):\n",
    "                # set up the taxis \n",
    "                taxis = [i, j, k]\n",
    "                \n",
    "                # select two index: subidx1 and subidx2\n",
    "                subidx1, subidx2 = 0, patch_size[channel] - 1\n",
    "                \n",
    "                # three cases based on the channel selection\n",
    "                sub_patch_ins1, sub_patch_outs1 = divid_channel(norm_patch_ins, \n",
    "                                                                norm_patch_outs, channel, \n",
    "                                                                i, j, k, subidx1)\n",
    "                sub_patch_ins2, sub_patch_outs2 = divid_channel(norm_patch_ins, \n",
    "                                                                norm_patch_outs, channel, \n",
    "                                                                i, j, k, subidx2)\n",
    "                \n",
    "                # check the two slices\n",
    "                pass1, val11, lcriteria11, hcriteria11, val12, criteria12 = filter_2d(sub_patch_ins1, sub_patch_outs1, \n",
    "                                  norm_slice_max[step[channel]*taxis[channel]+subidx1], \n",
    "                                  thresh_low_ratio, thresh_high_ratio, thresh_diff_ratio, verbose)\n",
    "                pass2, val21, lcriteria21, hcriteria21, val22, criteria22 = filter_2d(sub_patch_ins2, sub_patch_outs2, \n",
    "                                  norm_slice_max[step[channel]*taxis[channel]+subidx2], \n",
    "                                  thresh_low_ratio, thresh_high_ratio, thresh_diff_ratio, verbose)\n",
    "                            \n",
    "                if pass1 and pass2:\n",
    "                    saved_patch_ins.append(norm_patch_ins[i, j, k])\n",
    "                    saved_patch_outs.append(norm_patch_outs[i, j, k])\n",
    "                #else:\n",
    "                    #print (val11, lcriteria11, hcriteria11, val12, criteria12)\n",
    "                    #print (val21, lcriteria21, hcriteria21, val22, criteria22)\n",
    "                    #disp_3d(norm_patch_ins[i, j, k], norm_patch_outs[i, j, k])\n",
    "                    \n",
    "    return np.array(saved_patch_ins), np.array(saved_patch_outs)\n",
    "\n",
    "\n",
    "def divid_channel(norm_patch_ins, norm_patch_outs, channel, i, j, k, subidx1):\n",
    "    if channel == 0:\n",
    "        sub_patch_ins = norm_patch_ins[i,j,k,subidx1]\n",
    "        sub_patch_outs = norm_patch_outs[i,j,k,subidx1]\n",
    "    elif channel == 1:\n",
    "        sub_patch_ins = norm_patch_ins[i,j,k,subidx1]\n",
    "        sub_patch_outs = norm_patch_outs[i,j,k,subidx1]\n",
    "    elif channel == 2:\n",
    "        sub_patch_ins = norm_patch_ins[i,j,k,subidx1]\n",
    "        sub_patch_outs = norm_patch_outs[i,j,k,subidx1]\n",
    "    else :\n",
    "        raise NotImplementedError('Channel [{:s}] not recognized.'.format(str(channel)))\n",
    "    return sub_patch_ins, sub_patch_outs \n",
    "\n",
    "\n",
    "def disp_3d(volume_ins, volume_outs):\n",
    "    \"\"\"\n",
    "    a helper function to display the all 3 central slice in the 3 axis\n",
    "    * the lowres image\n",
    "    * the highres image\n",
    "    * the absolute difference between the lowres image and the highres image\n",
    "    \n",
    "    ## an assumption here is that the volume is a cubic (n*n*n)\n",
    "    args:\n",
    "    -----\n",
    "    volume_ins: a 3d numpy array (low-res)\n",
    "    volume_outs: a 3d numpy array (high-res)\n",
    "    \n",
    "    return:\n",
    "    -----\n",
    "    None\n",
    "    \"\"\"\n",
    "    nrow, ncol, nchan = volume_ins.shape\n",
    "    # an assumption for using stack\n",
    "    assert nrow == ncol and ncol == nchan\n",
    "    assert volume_ins.shape == volume_outs.shape\n",
    "    \n",
    "    # set up the rows\n",
    "    lowres_val = np.hstack((volume_ins[nrow//2], volume_ins[:,ncol//2,:], volume_ins[...,nchan//2]))\n",
    "    highres_val = np.hstack((volume_outs[nrow//2], volume_outs[:,ncol//2,:], volume_outs[...,nchan//2]))\n",
    "    diff = np.abs(volume_ins - volume_outs)\n",
    "    diff_val = np.hstack((diff[nrow//2], diff[:,ncol//2,:], diff[...,nchan//2]))\n",
    "    \n",
    "    # display\n",
    "    #plt.imshow(np.vstack((lowres_val, highres_val, diff_val)), clim=[0,5], cmap='gray')\n",
    "    #plt.show()\n",
    "    #plt.close()\n",
    "    \n",
    "    \n",
    "def filter_2d(patch_ins, patch_outs, pixel_max, thresh_low_ratio, thresh_high_ratio, thresh_diff_ratio, verbose):\n",
    "    \"\"\"\n",
    "    used to extract the patches that could be used in the training sets.\n",
    "    (tested on the 2D T2 axial => thresh_low_ratio=0.3, thresh_diff_ratio=0.05)\n",
    "    \n",
    "    args:\n",
    "    --------\n",
    "    patch_ins : the numpy array for the target low-res patch (2d)\n",
    "    patch_outs: the numpy array for the target high-res patch (2d)\n",
    "    pixel_max: the max value for the current image(2d)\n",
    "    thresh_low_ratio: a ratio used to filter out the background area\n",
    "    thresh_diff_ratio: a ratio used to filter out the area with intensity difference\n",
    "    verbose: verbose mode\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    boolean var: whether the current patch should be filtered out or kept\n",
    "    \"\"\"\n",
    "    patch_val = np.mean(patch_ins)\n",
    "    patch_diff = np.mean(np.abs(patch_ins - patch_outs))\n",
    "    if patch_val < thresh_high_ratio * pixel_max and patch_val > thresh_low_ratio * pixel_max and patch_diff < thresh_diff_ratio * pixel_max:\n",
    "        return True, patch_val, thresh_low_ratio * pixel_max, thresh_high_ratio * pixel_max, patch_diff, thresh_diff_ratio * pixel_max\n",
    "    else:\n",
    "        return False, patch_val, thresh_low_ratio * pixel_max, thresh_high_ratio * pixel_max, patch_diff, thresh_diff_ratio * pixel_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "(224, 512, 512) 1.002882 115.22112\n",
      "cnt= 57200\n"
     ]
    }
   ],
   "source": [
    "shared_path = '/home/subtle/Data/Long/data/hoag_T1_zoomed/S1'\n",
    "saved_path = \"/home/subtle/Long/\"\n",
    "cnt = 0\n",
    "for element in os.listdir(shared_path):\n",
    "    file = h5py.File(os.path.join(shared_path, 'cor_T_Id0017.h5'), 'r')\n",
    "    norm_low = file[\"input\"][:][...,0]\n",
    "    norm_high = file[\"output\"][:][...,0]\n",
    "    pixel_mean = file[\"mean\"][:][0]\n",
    "    print (norm_low.shape, np.mean(norm_low), pixel_mean)\n",
    "    saved_patch_ins, saved_patch_outs = filter_3d(norm_low, norm_high, (32,32,32), (8,16,16), 0.3, 0.6, 0.05, 1, False)\n",
    "    cnt += saved_patch_ins.shape[0]\n",
    "    with h5py.File(os.path.join(saved_path, 'p32_3d_S1_lr_hr' + element), 'w') as hf:\n",
    "        hf.create_dataset(\"input\", data=saved_patch_ins[..., np.newaxis], compression=\"gzip\")\n",
    "        hf.create_dataset(\"output\", data=saved_patch_outs[...,np.newaxis], compression=\"gzip\")\n",
    "        hf.create_dataset(\"nslice\", data=[saved_patch_ins.shape[0]], compression='gzip')\n",
    "        hf.create_dataset(\"mean\", data=[pixel_mean], compression='gzip')\n",
    "    \n",
    "print (\"cnt=\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
