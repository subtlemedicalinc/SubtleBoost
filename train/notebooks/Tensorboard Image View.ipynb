{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 19:18:50.996068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 19:18:51.105708: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-17 19:18:51.105742: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorboard.backend.event_processing.event_accumulator.EventAccumulator at 0x7f69dc898a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import PIL.Image as Image\n",
    "import io\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# sns.set(style=\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "# import subtle.utils.io as suio\n",
    "\n",
    "plt.set_cmap('gray')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "def byte_to_array(img_bstr):\n",
    "    return np.array(Image.open(io.BytesIO(img_bstr)))\n",
    "\n",
    "log_path = '/home/srivathsa/projects/studies/gad/stanford/train/tb/stanford_sri_enh_vgg_b4_1681690282/'\n",
    "log_path += 'events.out.tfevents.1681690283.accio'\n",
    "num_files = len(glob('{}/*'.format(log_path)))\n",
    "\n",
    "tf_size_guidance = {\n",
    "    'compressedHistograms': 0,\n",
    "    'images': 200,\n",
    "    'scalars': 0,\n",
    "    'histograms': 0\n",
    "}\n",
    "\n",
    "event_acc = EventAccumulator(log_path, size_guidance=tf_size_guidance)\n",
    "event_acc.Reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disp_img(key):\n",
    "    img_array = []\n",
    "\n",
    "    img_dim = 192\n",
    "    #img_dim = 256\n",
    "    img_w = 160\n",
    "\n",
    "    imgs = event_acc.Images(key)\n",
    "    \n",
    "    for idx, img in enumerate(imgs):\n",
    "        img_bstr = img.encoded_image_string\n",
    "        img = byte_to_array(img_bstr)\n",
    "        \n",
    "        img_array.append(img)\n",
    "        \n",
    "        \n",
    "    img_array = np.array(img_array)\n",
    "\n",
    "#     num_parts = img_array.shape[-1] // img_dim\n",
    "#     img_array = np.reshape(img_array, (num_files, img_dim, num_parts, img_dim))\n",
    "    \n",
    "    view_idx = [0]\n",
    "#     view_idx = [4, 6, 7, 8, 9]\n",
    "#     view_idx = [5, 7]\n",
    "\n",
    "#     sum_img = np.sum(img_array[:, :, 6:9], axis=2)\n",
    "#     pre_con = img_array[:, :, 0]\n",
    "#     sum_img = np.interp(sum_img, (sum_img.min(), sum_img.max()), (pre_con.min(), pre_con.max()))\n",
    "#     diff_img = sum_img - pre_con\n",
    "        \n",
    "    img_disp = img_array[..., view_idx]\n",
    "#     img_disp = np.append(img_disp, diff_img[:, :, None, :], axis=2)\n",
    "#     img_disp = np.reshape(img_disp, (img_disp.shape[0], img_disp.shape[1], -1))\n",
    "    \n",
    "    return img_disp.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f3d7486062473b9e8101347c4cadc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=49, description='idx', max=99), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_keys = event_acc.images.Keys()\n",
    "\n",
    "img_disp = get_disp_img('Validation_0')\n",
    "img_disp = img_disp.reshape((img_disp.shape[0], 512, 5, 512)).transpose(2, 0, 1, 3)\n",
    "pre, low, full, enh, pred = img_disp\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, pre.shape[0]-1, 1)):\n",
    "    plt.imshow(np.hstack([full[idx], pred[idx]]))\n",
    "    plt.title('Index {}'.format(idx))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'train/outputs'\n",
    "img_array = []\n",
    "imgs = event_acc.Images(key)\n",
    "\n",
    "for idx, img in enumerate(imgs):\n",
    "    img_bstr = img.encoded_image_string\n",
    "    img_el = img_array.append(byte_to_array(img_bstr))\n",
    "\n",
    "img_array = np.array(img_array)\n",
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array[-52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_keys = event_acc.images.Keys()\n",
    "print(img_keys)\n",
    "\n",
    "img_disp_1 = get_disp_img('train/targets')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_1.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_1[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_keys = event_acc.images.Keys()\n",
    "print(img_keys)\n",
    "\n",
    "img_disp_1 = get_disp_img('train/inputs')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_1.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_1[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_2 = get_disp_img('NO6_134')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_2.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_2[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_3 = get_disp_img('NO18_110')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_3.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_3[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_4 = get_disp_img('Case1_69')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_4.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_4[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_disp_5 = get_disp_img('Case1_96')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_5.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_5[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_disp_6 = get_disp_img('Brain3H-600437593_74')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_6.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_6[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_7 = get_disp_img('Brain5H-601047608_102')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_7.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_7[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_disp_8 = get_disp_img('Brain5H-601047608_114')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_8.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_8[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_9 = get_disp_img('NO14_82')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_9.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_9[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_10 = get_disp_img('NO18_110')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_10.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_10[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_11 = get_disp_img('NO14_107')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_11.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_11[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_12 = get_disp_img('NO104_121')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_12.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_12[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_13 = get_disp_img('NO104_126')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_13.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_13[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_14 = get_disp_img('NO115_121')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_14.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_14[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_15 = get_disp_img('NO120_101')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_15.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_15[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_16 = get_disp_img('NO122_141')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_16.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_16[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_17 = get_disp_img('NO129_91')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_17.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_17[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_disp_18 = get_disp_img('NO130_111')\n",
    "\n",
    "@interact\n",
    "def show_tb_imgs(idx=(0, img_disp_18.shape[0]-1, 1)):\n",
    "    plt.imshow(img_disp_18[idx], vmax=180)\n",
    "    plt.title('Index {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fboost models - combined\n",
    "\n",
    "### Fboost super model (7 + 1 = 8 channels final encoder input)\n",
    "\n",
    "# Case1 - 10, 43, 46, 56, \n",
    "# NO6\n",
    "# NO14\n",
    "\n",
    "# NO39\n",
    "# NO44\n",
    "# NO57\n",
    "# NO65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fboost Models - Indiv\n",
    "\n",
    "### T1 + UAD\n",
    "\n",
    "# Case1 - 4, 8, 9, 12, 14, 20, 22, 25, 27, 29, 30, 35, 37, 41, 46, 58, 60, 62, 67, 70, 73, 80, 85, 90, 99\n",
    "# NO6 - 4, 20, 29, 67, 90\n",
    "# NO14 - 37, 73\n",
    "\n",
    "# NO39 - 37\n",
    "# NO44\n",
    "# NO57 - 4, 12, 14, 20, 22, 25, 29, 62\n",
    "# NO65 - \n",
    "\n",
    "# Overall candidates - 4, 20, 29\n",
    "\n",
    "### T1 + FLAIR\n",
    "\n",
    "# Case1 - 4, 9, 10, 13, 15, 16, 25, 29, 31, 34, 35, 38, 42, 44, 45, 49, 58, 59, 69, 74, 77, 83, 85, 89, 97\n",
    "# NO6 - 9\n",
    "# NO14\n",
    "\n",
    "# NO39 - 4, 15, 16, 29, 35, 42, 44, 45, 49, 58, 59, 69, 89, 97\n",
    "# NO44 - \n",
    "# NO57 - 4, 42, 69, 89, 97\n",
    "# NO65\n",
    "\n",
    "# Overall candidates - 4, 89, 97\n",
    "\n",
    "\n",
    "### T1 + T2\n",
    "\n",
    "# Case1 - 3, 9, 12, 23, 28, 31, 38, 42, 51, 56, 88, 99\n",
    "# NO6 - 3, 7, 9, 15, 21, 23, 28, 31, 38, 42, 51, 56, 62, 87, 88, 99\n",
    "# NO14 - 9, 15, 21, 23, 31, 38, 51, 56, 62, 88\n",
    "\n",
    "# NO39 - 9, 31, 38, 56, 87\n",
    "# NO44 - 9, 21, 51, 56, 87\n",
    "# NO57 - 9, 31, 56, 62, 88, 99\n",
    "# NO65 - \n",
    "\n",
    "# Overall candidates - 9, 31, 38, 56, 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_idxs = [4, 20]\n",
    "\n",
    "# img_view = np.vstack(img_disp[view_idxs])\n",
    "# plt.imshow(img_view)\n",
    "\n",
    "### no_10pct\n",
    "\n",
    "# Case1\n",
    "# NO6\n",
    "# NO14\n",
    "\n",
    "# NO39\n",
    "# NO44\n",
    "# NO57\n",
    "# NO65\n",
    "\n",
    "\n",
    "for view_idx in view_idxs:\n",
    "    plt.imshow(img_disp[view_idx])\n",
    "    plt.title('view idx={}'.format(view_idx))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VGG MPR Models\n",
    "\n",
    "### t2_uadch7_enhuad\n",
    "\n",
    "# Case1\n",
    "# NO6\n",
    "# NO14\n",
    "\n",
    "# NO39 - 5, 24, 31\n",
    "# NO44 - 5, 24, 31\n",
    "# NO57 - 5, 10, 31\n",
    "# NO65 - 24, 31\n",
    "\n",
    "# Overall candidates - 5, 24, 31\n",
    "\n",
    "### t2_uadch1_enhuad\n",
    "\n",
    "# Case1\n",
    "# NO6\n",
    "# NO14\n",
    "\n",
    "# NO39 - 7, 14, 17\n",
    "# NO44 - 13, 17\n",
    "# NO57 - 13, 17\n",
    "# NO65 - 14, 18\n",
    "\n",
    "# Overall candidates - 14, 17, 18\n",
    "\n",
    "### fl_uadch7_enhuad\n",
    "\n",
    "# Case1\n",
    "# NO6\n",
    "# NO14\n",
    "\n",
    "# NO39 - 1, 29\n",
    "# NO44 - 6\n",
    "# NO57 - 1, 30\n",
    "# NO65 - 29, 30\n",
    "\n",
    "# Overall candidates - 1, 29, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T2 Models\n",
    "\n",
    "### L1 + SSIM\n",
    "# Case1 - 0, 23, 73\n",
    "# NO6 - 23, 27, 30, 73\n",
    "# NO14 - 23, 30, 73, 75\n",
    "\n",
    "# NO39 - 5, 41, 55\n",
    "# NO44 - 13, 18, 22, 30, 40, 55, 61\n",
    "# NO57 - 13, 22, 30, 55, 61, 79\n",
    "\n",
    "# Overall candidates - 13, 22, 30, 40, 41, 55, 61\n",
    "\n",
    "### T2 Reg Enh with UAD input\n",
    "# Case1 - 7, 11, 58\n",
    "# NO6 - 7, 12, 17, 25\n",
    "# NO14 - 11, 14, 20, 61\n",
    "\n",
    "# NO39 - 7, 11, 14\n",
    "# NO44 - 7, 14\n",
    "# NO57 - 11, 13, 14\n",
    "# NO65 - 7, 11, 14\n",
    "\n",
    "# Overall candidates - 7, 11, 14\n",
    "\n",
    "### T2 Enh UAD with UAD input\n",
    "# Case1 - 12, 14, 22, 28, 34, 61, 66, 83\n",
    "# NO6 - 22, 29, 34, 41, 61\n",
    "# NO14 - 14, 23, 66\n",
    "\n",
    "# NO39 - 14, 23, 28, 41\n",
    "# NO44 - 14, 28, 34, 41\n",
    "# NO57 - 14, 28, 41\n",
    "# NO65 - 14, 23, 28, 41\n",
    "\n",
    "# Overall candidates - 14, 28, 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FLAIR models\n",
    "\n",
    "### FLAIR input L1 + SSIM\n",
    "\n",
    "# Case1 - 8, 11, 20, 23, 40, 90\n",
    "# NO6 - 23, 30, 32, 38, 47, 60, 73, 90\n",
    "# NO14 - 20, 23, 38, 90\n",
    "\n",
    "# NO39 - 23, 90\n",
    "# NO44 - 23, 38\n",
    "# NO57 - 38, 90\n",
    "# NO65 - 23\n",
    "\n",
    "### uadenh_basic\n",
    "\n",
    "# Case1 - 7, 10\n",
    "# NO6 - 7, 10, 29, 36\n",
    "# NO14 - 7, 10, 29, 36, 54, 80\n",
    "\n",
    "# NO39 - 29\n",
    "# NO44 - 29\n",
    "# NO57 - 7, 36\n",
    "# NO65 - 7, 12, 29, 36\n",
    "\n",
    "### enh_basic\n",
    "\n",
    "# Case1\n",
    "# NO6\n",
    "# NO14\n",
    "\n",
    "# NO39 - 7, 10, 15\n",
    "# NO44\n",
    "# NO57 - 14, 20, 42, 52, 58\n",
    "# NO65\n",
    "\n",
    "### uadip_basic\n",
    "\n",
    "# Case1\n",
    "# NO6\n",
    "# NO14\n",
    "\n",
    "# NO39 - 64, 80, 83, 91\n",
    "# NO44\n",
    "# NO57 - 83, 91\n",
    "# NO65\n",
    "\n",
    "\n",
    "### uadip_uadenh\n",
    "\n",
    "# Case1\n",
    "# NO6\n",
    "# NO14\n",
    "\n",
    "# NO39 - 9, 27, 28, 37, 54\n",
    "# NO44 - 54\n",
    "# NO57 - 7, 54, 67\n",
    "# NO65 - 37, 54\n",
    "\n",
    "# Overall candidates - 9, 37, 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = suio.load_file('/home/srivathsa/projects/studies/gad/tiantan/preprocess/data_t2_fl/NO14.h5')\n",
    "uad = np.load('/home/srivathsa/projects/studies/gad/tiantan/preprocess/uad_masks_fl/NO14.npy')\n",
    "sl = 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[sl, 2] * uad[sl] + data[sl, 2] * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(uad[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/srivathsa/projects/studies/gad/tiantan/inference/debug/X_88.npy')\n",
    "Y = np.load('/home/srivathsa/projects/studies/gad/tiantan/inference/debug/Y_88.npy')\n",
    "print(data.shape)\n",
    "print(Y.shape)\n",
    "plt.imshow(Y[0, ..., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
