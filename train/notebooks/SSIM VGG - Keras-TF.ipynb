{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2bb1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/srivathsa/miniconda3/envs/py35gad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/home/srivathsa/projects/SubtleGad/train/subtle/utils/hyperparameter.py:8: UserWarning: Module test_tube not found - hyperparameter related functions cannot be used\n",
      "  warnings.warn('Module test_tube not found - hyperparameter related functions cannot be used')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import subtle.utils.io as suio\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "plt.set_cmap('gray')\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.imagenet_utils import preprocess_input as vgg_preprocess\n",
    "from keras.models import Model\n",
    "\n",
    "def extract_image_patches(x, ksizes, ssizes, padding='same', data_format='channels_last'):\n",
    "    bs_i, w_i, h_i, ch_i = K.int_shape(x)\n",
    "    kernel = [1, ksizes[0], ksizes[1], 1]\n",
    "    strides = [1, ssizes[0], ssizes[1], 1]\n",
    "\n",
    "    patches = tf.extract_image_patches(x, kernel, strides, [1, 1, 1, 1], padding)\n",
    "    bs, w, h, ch = K.int_shape(patches)\n",
    "    reshaped = tf.reshape(patches, [-1, w, h, tf.floordiv(ch, ch_i), ch_i])\n",
    "    final_shape = [-1, w, h, ch_i, ksizes[0], ksizes[1]]\n",
    "    patches = tf.reshape(tf.transpose(reshaped, [0, 1, 2, 4, 3]), final_shape)\n",
    "\n",
    "    patches = K.permute_dimensions(patches, [0, 1, 2, 4, 5, 3])\n",
    "\n",
    "    return patches\n",
    "\n",
    "def ssim_loss(y_true, y_pred, kernel=(3, 3), k1=.01, k2=.03, kernel_size=3, max_value=1.):\n",
    "    # ssim parameters\n",
    "    cc1 = (k1 * max_value) ** 2\n",
    "    cc2 = (k2 * max_value) ** 2\n",
    "\n",
    "    # extract patches\n",
    "    y_true = K.reshape(y_true, [-1] + list(K.int_shape(y_true)[1:]))\n",
    "    y_pred = K.reshape(y_pred, [-1] + list(K.int_shape(y_pred)[1:]))\n",
    "\n",
    "    patches_true = extract_image_patches(y_true, kernel, kernel, 'VALID', K.image_data_format())\n",
    "    patches_pred = extract_image_patches(y_pred, kernel, kernel, 'VALID', K.image_data_format())\n",
    "    \n",
    "    bs, w, h, c1, c2, c3 = K.int_shape(patches_pred)\n",
    "    patches_true = K.reshape(patches_true, [-1, w, h, c1 * c2 * c3])\n",
    "    patches_pred = K.reshape(patches_pred, [-1, w, h, c1 * c2 * c3])\n",
    "\n",
    "    # Get mean\n",
    "    u_true = K.mean(patches_true, axis=-1)\n",
    "    u_pred = K.mean(patches_pred, axis=-1)\n",
    "    print('prod', K.eval(u_true * u_pred).mean())\n",
    "\n",
    "    # Get variance\n",
    "    var_true = K.var(patches_true, axis=-1)\n",
    "    var_pred = K.var(patches_pred, axis=-1)\n",
    "\n",
    "    # Get covariance\n",
    "    covar_true_pred = K.mean(patches_true * patches_pred, axis=-1) - u_true * u_pred\n",
    "    \n",
    "    # compute ssim and dssim\n",
    "    ssim = (2 * u_true * u_pred + cc1) * (2 * covar_true_pred + cc2)\n",
    "    denom = (K.square(u_true) + K.square(u_pred) + cc1) * (var_pred + var_true + cc2)\n",
    "    ssim /= denom\n",
    "    \n",
    "    return K.mean((1.0 - ssim) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8ebb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptual_loss(y_true, y_pred, img_shape, resize_shape):\n",
    "    # From https://bit.ly/2HTb4t9\n",
    "\n",
    "    num_slices = int(y_pred.shape[-1])\n",
    "    print('num slices', num_slices)\n",
    "\n",
    "    vgg = VGG19(include_top=False, weights='imagenet', input_shape=img_shape)\n",
    "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "    loss_model.trainable = False\n",
    "\n",
    "    loss_vals = []\n",
    "\n",
    "    for idx in range(num_slices):\n",
    "        y_true_sl = K.expand_dims(y_true[..., idx])\n",
    "        y_pred_sl = K.expand_dims(y_pred[..., idx])\n",
    "\n",
    "        if resize_shape > 0:\n",
    "            # For 512x512 images, VGG-19 creates some grid artifacts because the\n",
    "            # original network is trained with 224x224 images\n",
    "            y_true_sl = tf.image.resize(y_true_sl, (resize_shape, resize_shape))\n",
    "            y_pred_sl = tf.image.resize(y_pred_sl, (resize_shape, resize_shape))\n",
    "\n",
    "        y_true_3c = K.concatenate([y_true_sl, y_true_sl, y_true_sl])\n",
    "        y_pred_3c = K.concatenate([y_pred_sl, y_pred_sl, y_pred_sl])\n",
    "\n",
    "        y_true_3c = vgg_preprocess(y_true_3c, mode='caffe')\n",
    "        y_pred_3c = vgg_preprocess(y_pred_3c, mode='caffe')\n",
    "        \n",
    "#         print(K.eval(y_true_3c).mean(), K.eval(y_pred_3c).mean())\n",
    "        \n",
    "        v1 = loss_model(y_true_3c)\n",
    "        v2 = loss_model(y_pred_3c)\n",
    "        \n",
    "#         print(K.eval(v1).mean(), K.eval(v2).mean())\n",
    "        mse = K.mean(K.square(v1 - v2))\n",
    "        loss_vals.append(mse)\n",
    "    \n",
    "    loss_vals = tf.stack(loss_vals)\n",
    "    return tf.math.reduce_mean(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9a3a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/slices/Patient_0088/ax/150.npy')\n",
    "data2 = np.load('/home/srivathsa/projects/studies/gad/stanford/preprocess/slices/Patient_0088/ax/155.npy')\n",
    "\n",
    "pre = data[0]\n",
    "low = data[1]\n",
    "\n",
    "full = data[2]\n",
    "full2 = data2[2]\n",
    "\n",
    "ip1 = K.constant(pre[None, ..., None].astype(np.float32))\n",
    "ip2 = K.constant(low[None, ..., None].astype(np.float32))\n",
    "ip3 = K.constant(full[None, ..., None].astype(np.float32))\n",
    "ip4 = K.constant(full2[None, ..., None].astype(np.float32))\n",
    "\n",
    "print(ip1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4005839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num slices 1\n",
      "689.9607\n"
     ]
    }
   ],
   "source": [
    "vgg_loss = perceptual_loss(ip3, ip4, img_shape=(512, 512, 3), resize_shape=0)\n",
    "print(K.eval(vgg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba5da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_val = K.eval(vgg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee04145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5532b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip1_3c = K.concatenate([ip1, ip1, ip1])\n",
    "ip2_3c = K.concatenate([ip2, ip2, ip2])\n",
    "ip1_pp = vgg_preprocess(ip1_3c)\n",
    "ip2_pp = vgg_preprocess(ip2_3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip1_img = K.eval(ip1_pp)\n",
    "\n",
    "plt.imshow(ip1_img[0, ..., 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip2_img = K.eval(ip2_pp)\n",
    "plt.imshow(ip2_img[0, ..., 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f2683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py35gad)",
   "language": "python",
   "name": "py35gad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
